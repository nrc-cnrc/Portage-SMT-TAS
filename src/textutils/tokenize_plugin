#!/bin/bash

# @file tokenize_plugin
# @brief This script is provided as an example of tokenize_plugin script, as
#        well as a default one.
#
# @author Samuel Larkin
#
# Technologies langagieres interactives / Interactive Language Technologies
# Inst. de technologie de l'information / Institute for Information Technology
# Conseil national de recherches Canada / National Research Council Canada
# Copyright 2012, Sa Majeste la Reine du Chef du Canada /
# Copyright 2012, Her Majesty in Right of Canada


## 
## Usage: tokenize_plugin SRC_LANG < in > out
## 
## Default tokenize plugin: to be called immediately prior to lowercasing
## but after preprocess_plugin and sentence splitting.  Important: must only
## perform tokenisation, not sentence splitting.
##
## Warning: currently, the tokenize plugin is only used by translate.pl if the
## source language is not one of "en", "fr", or "es", the languages supported by
## utokenize.pl.
##

if [ "$1" == "-help" -o "$1" == "-h" ]; then
    cat $0 | grep "^##" | cut -c4-
    exit 1
fi

test $# -eq 0 && echo "Missing language code argument" >&2 && exit 1
SOURCE_LANGUAGE=$1; shift

if [[ "$SOURCE_LANGUAGE" == "ch" ]]; then
   chinese_segmenter.pl
   # To use ICTCLAS, comment out chinese_segmenter.pl above, and uncomment the following:
   #set -o pipefail
   #iconv -c -f UTF-8 -t CN-GB |
   #   ictclas_preprocessing.pl |
   #   ictclas |
   #   ictclas_postprocessing.pl |
   #   iconv -c -f CN-GB -t UTF-8

#elif [[ "$SOURCE_LANGUAGE" == "xy" ]]; then
   # insert code or call program to tokenize text in language "xy" here,
   # reading STDIN and writing to STDOUT.

elif [[ "$SOURCE_LANGUAGE" == "ar" ]]; then
   export PATH=`dirname $0`:$PATH

   TMPFILE=`mktemp -d /tmp/ar_tokenization.XXXXXXXXXX` || exit 1
   #trap "rm -fr ${TMPFILE}" 0

   # TODO: fix the character set switching between Arabic and non Arabic
   cat | perl -ple '
      BEGIN {
         binmode( STDIN,  ":encoding(UTF-8)" );
         binmode( STDOUT, ":encoding(UTF-8)" );
      };

      s/[\r]?\n$/ /;
      s/^/ /;
      s/([\p{Arabic}])([^\p{Arabic}])/$1 $2/g;
      s/([^\p{Arabic}])([\p{Arabic}])/$1 $2/g;
      s/  +/ /g;
      s/^ //;
      s/ $//;
   ' > ${TMPFILE}/src

   # On balzac we define MADA.
   # On our vm, in our web stack we don't define MADA but we install it under $PORTAGE/bin.
   # FYI $PORTAGE on our vm doesn't have the same semantic as on balzac
   MADA_HOME=${MADA:-$PORTAGE/bin}

   # May be we could use a config that output simply FORM1 of ATB4MT but this
   # doesn't remove parse_tokan since we still need to do normalization and
   # tokenization of English.
   MADAX="perl ${MADA_HOME}/MADA+TOKAN.pl";
   CONFIG="${MADA_HOME}/config-files/template.madaconfig";
   ${MADAX} \
      config=${CONFIG} \
      file=${TMPFILE}/src \
      outputdir=${TMPFILE} \
      TOKAN_SCHEME="SCHEME=ATB4MT MARKNOANALYSIS" \
      2> ${TMPFILE}/log
   rc=$?
   if [ "$rc" != "0" -o ! -e "${TMPFILE}/src.bw.mada.tok" ]; then
      echo "ERROR: with MADA (tokenize_plugin)" >&2
      cat ${TMPFILE}/log >&2
      exit 1
   fi


   export PORTAGE_INTERNAL_CALL=1
   parse_tokan.pl 6 1 < ${TMPFILE}/src.bw.mada.tok
   rc=$?
   if [[ "$rc" != 0 ]]; then
      echo "ERROR: with parse_tokan.pl (tokenize_plugin)" >&2
      cat ${TMPFILE}/log >&2
      exit 1
   fi


else
   echo "Unsupported language: $SOURCE_LANGUAGE" >&2
   echo "tokenize_plugin fatal error: Unsupported language: $SOURCE_LANGUAGE; use utokenize.pl for languages it supports, or modify this plugin to call a third-party tokenizer." >&2
   exit 1

fi
