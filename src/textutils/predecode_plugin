#!/bin/bash
#
# @file predecode_plugin
# @brief Default pre-decoder plugin
#
# @author Michel Simard extended by Samuel Larkin
#
# COMMENTS:
#
# Technologies langagieres interactives / Interactive Language Technologies
# Inst. de technologie de l'information / Institute for Information Technology
# Conseil national de recherches Canada / National Research Council Canada
# Copyright 2010, Conseil national de recherches du Canada /
# Copyright 2010, National Research Council of Canada

##
## Usage: predecode_plugin SRC_LANG-TGT_LANG < in > out
##
## Default predecoding plugin: to be called immediately prior to
## decoding (but after tokenization, lowercasing, etc.).
## Among other things, the predecoding plugin must apply the rules parser.
##

# ######################################################## #
#               Quick configuration options                #
# ######################################################## #
# Some behaviours can be turned on and off here, although you can also do
# more advanced configuration by modifying the rest of the script below.

# Uncomment if you want to mark English numbers for rule-based translation to
# their French format, or French numbers to their English format.
# Note: has no effect unless the system is en->fr or fr->en.
MARK_NUMBERS_ENFR=1

# Uncomment to turn on ascii markup processing for Arabic
#CONVERT_ASCII_TO_MARKUP=1

# ######################################################## #
#            End of Quick configuration options            #
# ######################################################## #

if [[ $1 = -help || $1 = -h ]]; then
    cat $0 | grep "^##" | cut -c4-
    exit 1
fi

[[ $# = 0 ]] && echo "Missing language code argument" >&2 && exit 1
SRC_TGT=$1; shift
declare -a LANGS
LANGS=(`echo $SRC_TGT | tr '-' ' '`)
SOURCE_LANGUAGE=${LANGS[0]}
TARGET_LANGUAGE=${LANGS[1]}

# TODO: How to pickup the proper plugins/fixedTerms if this is the default script located in /opt/PortageII/bin/?
FIXED_TERMS_MODEL_DIRECTORY=${FIXED_TERMS_MODEL_DIRECTORY:-$(dirname $0)}

set -o pipefail

if [[ -s ${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/tm ]]; then
   if [[ ! -s ${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/lm ]]; then
      echo -e '\n\\data\\\nngram 1=2\n\n\\1-grams:\n0\t</s>\n-99\t<s>\n\n\\end\\' > ${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/lm
   fi

   # If fixed terms are available, apply them.
   #perl -ple 's/<([^>]+)>(?:.*?)<\/\1>/$a=$&; $a=s#([\\<>])#\\\1#g/gex' |
   # IMPORTANT NOTE: YES we double canoe-escaple here if we want the
   # original xmlish markup to be escape while it passes through canoe
   # which unescapes them.
   LOCK_FILE=${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/tm.lock
   touch $LOCK_FILE
   canoe-escapes.pl -add | canoe-escapes.pl -add \
   | utf8_filter \
   | flock --shared $LOCK_FILE canoe \
      -f /dev/null \
      -load-first \
      -oov pass \
      -ttable-multi-prob ${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/tm \
      -lmodel-file ${FIXED_TERMS_MODEL_DIRECTORY}/fixedTerms/lm \
      -ttable-limit 100 \
      -regular-stack 100 \
      -ftm 1.0 \
      -lm 0.0 \
      -tm 1.0 \
      -distortion-limit 0 \
   2> /dev/null
else
   # If you have a rules parser, replace the canoe-escapes.pl call by a call to
   # your rules parser. The rules parser must also escape literal use of the
   # following characters in the input text: '<', '>', '\'.
   # TODO should this be in front of the fixed terms regardless?
   canoe-escapes.pl -add | utf8_filter
fi \
| if [[ -n "$MARK_NUMBERS_ENFR" ]]; then
   if [[ $SOURCE_LANGUAGE == en && $TARGET_LANGUAGE == fr ]]; then
      mark-numbers-en2fr.pl
   elif [[ $SOURCE_LANGUAGE == fr && $TARGET_LANGUAGE == en ]]; then
      mark-numbers-fr2en.pl
   else
      cat
   fi
else
   cat
fi \
| if [[ -n "$CONVERT_ASCII_TO_MARKUP" ]]; then
   # The Perl line in the middle is used to wrap non-Arabic tokens
   # (actually: tokens that MADA labelled as non-Arabic because they
   # contained at least one ASCII letter) into Portage "translate as-is"
   # rules. This to avoid unwanted translations when Buckwalter
   # transliterations accidentally collide with English words. Initial
   # "__ascii__" prefixing is performed within tokenize_plugin. [MS]
   perl -pe 'sub escapeQuotes { my ($s)=@_; $s =~ s/\"/\\\"/g; return $s };$_=~s{__ascii__([^\s]+)}{"<ascii target=\"".escapeQuotes($1)."\"> $1 </ascii>"}ge;'
else
   cat
fi
