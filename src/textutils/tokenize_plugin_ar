#!/usr/bin/env perl
# @file tokenize_plugin
# @brief  A special tokenize_plugin to replace MADA's slow preprocessing.  This
# scrpts combines all preprocessing steps done for a NIST evaluation.
#
# @author Samuel Larkin -- hacks by Michel Simard
#
# Technologies langagieres interactives / Interactive Language Technologies
# Inst. de technologie de l'information / Institute for Information Technology
# Conseil national de recherches Canada / National Research Council Canada
# Copyright 2014, Sa Majeste la Reine du Chef du Canada /
# Copyright 2014, Her Majesty in Right of Canada


use strict;
use warnings;
use utf8;  # This script has a unicode code point \xB7
use MADA::MADATools;
use ULexiTools;
use JSON;
use Time::HiRes qw ( time );
use FindBin qw($Bin);  # Figures out this script location directory.
# Add this script's path to the end of the include path that way, the effective
# tokenize::Arabic::Data will user defined first then as a fallback we will use
# the default lib located next to this script.
BEGIN { push(@INC, $Bin) }
#warn join(" : ", @INC);
use tokenize::Arabic::Data;
warn "Using ", $INC{'tokenize/Arabic/Data.pm'}, " for the tokenization\n";


# This is a utf8 handling script => io should be in utf8 format
# ref: http://search.cpan.org/~tty/kurila-1.7_0/lib/open.pm
# We need UTF-8 to be able to properly lowercase the input.
use open IO => ':encoding(utf-8)';
use open ':std';  # <= indicates that STDIN and STDOUT are utf8


sub usage {
   local $, = "\n";
   print STDERR @_, "";
   $0 =~ s#.*/##;
   print STDERR "
Usage: $0 ar [options] [IN [OUT]]

  Specialized tokenize_plugin for Arabic that make use of a precompiled map
  instead of MADA.

  Tokenization for Arabic text.  This does:
  - Howard's preprocessing to split Arabic from non-Arabic characters
  - MADA's preprocessing
     - clean the UTF-8
     - tag English strings
     - separate punctuation & numbers
     - convert UTF-8 to Buckwalter
  - parse tokan to tokenize latin words
  - perform tokenization by apply a predefined mapping


Notes:
  to be compatible with the normal tokenize_plugin script for portagelive, you
  MUST specify ar as the language code.

Options:

  -p(repoOnly)  do not perform tokenization (do Howard's preprocessing, MADA's
                preprocessing & parse tokan).
  -n            Mark non Arabic words.  [don't]
                Convert MADA's markup form:
                \@\@LAT\@\@WORD
                to:
                __ascii__WORD
                You will need to change predecode_plugin to process __ascii__.
                This option has no effect when used with -prepoOnly.
  -w            Remove beginning of sentence's w+. [don't]
                This option has no effect when used with -prepoOnly.
  -m            xmlishify hashtags. [don't]
                This option has no effect when used with -prepoOnly.
                You will need to enalbe xml2hashtag.pl in postprocess_plugin.

  -h(elp)       print this help message
  -v(erbose)    increment the verbosity level by 1 (may be repeated)
  -d(ebug)      print debugging information
  -q(uiet)      disable verbose messages.
";
   exit 1;
}

use Getopt::Long;
Getopt::Long::Configure("no_ignore_case");
# Note to programmer: Getopt::Long automatically accepts unambiguous
# abbreviations for all options.
my $verbose = 1;
GetOptions(
   preproOnly  => \my $preproOnly,
   n           => \my $markNonArabicWord,
   w           => \my $removeWa,
   m           => \my $markHashTag,

   help        => sub { usage },
   verbose     => sub { ++$verbose },
   quiet       => sub { $verbose = 0 },
   debug       => \my $debug,
) or usage;

my $SOURCE_LANGUAGE = shift or die "You must provide ar as the language code.";
die "Wrong language, this script is for Arabic only." if (lc($SOURCE_LANGUAGE) ne "ar");


my $MADA_HOME = $ENV{MADA_HOME} || "/opt/PortageII/bin";
print STDERR "MADA_HOME is $MADA_HOME\n";
die "You must define MADA_HOME" unless(defined($MADA_HOME));

# Parse tokan stuff.
my $sep = "Â·";
my $oov = undef;
my $nolc = 0;
my $skipTokenization = undef;

# Make ULexitools arguments explicit by giving them variable names.
my $notok  = 0;
my $pretok = 0;
my $xtags  = 0;
setTokenizationLang("en");


loadMADACleanUpMap("$MADA_HOME/common-tasks/clean-utf8-MAP");
my $word2morpho = undef;
unless ($preproOnly) {
   $word2morpho = loadMappingData();
}

my $now_fractions = time;
while (defined(my $input = <STDIN>)) {
   chomp($input);
   if ($input eq '') {
      print $input, "\n";
      next;
   }

   # Need plain format for buckwalterizing.
   # This should be  harmless in any case.
   # We will escape entity after buckwalterizing.
   $input =~ s/&lt;/</g;
   $input =~ s/&gt;/>/g;
   $input =~ s/&amp;/&/g;

   # Howard's preprocessing where we split Arabic characters from non-Arabic
   # characters.

   debug("[[Input = \n\"$input\" ]]\n");

   $input = HowardsPrepro($input);
   debug("[[ --> HowardsPrepro \n--> \"$input\" ]]\n");

   # MADA's preprocessing.
   $input = MADAsPrepro($input);
   debug("[[ --> MADAsPrepro \n--> \"$input\" ]]\n");

   # Prefix non-Arabic (@@LAT@@) tokens with "__ascii__". This is later handled
   # in predecode_plugin. [MS]
   unless ($preproOnly) {
      if ($markNonArabicWord) {
         $input = markNonArabic($input);
      }
   }

   # Parse tokan.
   $input = parse_tokan($input);
   debug("[[ --> parse_tokan \n--> \"$input\" ]]\n");

   # Apply the map
   unless ($preproOnly) {
      $input = tokenizeArabic($input, $word2morpho);

      debug("[[ --> tokenizeArabic \n--> \"$input\" ]]\n");

      # Remove initial "w+" -- moved here from predecode_plugin [MS]
      if (defined($removeWa)) {
         $input =~ s/^w\+\s+//;
      }

      # Treat hashtags as markup [MS]
      if (defined($markHashTag)) {
         # Protect xml entity from the decoder.
         # Espacially the buckwalter's encoded characters "<", ">" & "&"
         $input =~ s/&/&amp;/g;
         $input =~ s/</&lt;/g;
         $input =~ s/>/&gt;/g;

         $input = markHashtags($input);
         debug("[[ --> markHashtags \n--> \"$input\" ]]\n");
      }
   }

   print $input if (defined($input));
   print "\n";
}
printf(STDERR "Map in %3.3fms\n", 1000 * (time - $now_fractions));




sub HowardsPrepro {
   my $input = shift;
   die "You need to provide a sentence." unless(defined($input));

   $input =~ s/[\r]?\n$/ /;
   $input =~ s/^/ /;
   $input =~ s/(\p{Script:Arabic}\p{General_Category:Mark}*)([^\p{Script:Arabic}\p{General_Category:Mark}])/$1 $2/g;
   $input =~ s/([^\p{Script:Arabic}\p{General_Category:Mark}])(\p{Script:Arabic}\p{General_Category:Mark}*)/$1 $2/g;
   $input =~ s/  +/ /g;
   $input =~ s/^ //;
   $input =~ s/ $//;

   return $input;
}


sub MADAsPrepro {
   my $input = shift;
   die "You need to provide a sentence." unless(defined($input));

   my $result = 1;
   ($result, $input) =  &MADATools::cleanUTF8String($input);

   die "$0: Error - Empty UTF8 cleaning map file discovered.\n" if ( $result != 1 );

   $input = &MADATools::tagEnglishInString($input, "tag", "noid");
   $input = &MADATools::separatePunctuationAndNumbers($input, "utf-8", "no");
   $input = &MADATools::convertUTF8ToBuckwalter($input);

   return $input;
}


sub normalize {
   my ($in) = @_;
   my $out = $in;
   if ($out =~ s/\@\@LAT\@\@//g) {
      unless ($skipTokenization) {
         my $para = $out;
         $out = '';
         my @token_positions = tokenize($para, $pretok, $xtags);
         for (my $i = 0; $i < $#token_positions; $i += 2) {
            $out .= " " if ($i > 0);
            $out .= get_collapse_token($para, $i, @token_positions, $notok || $pretok);
         }
         chomp($out);
      }
      $out = lc($out) unless($nolc);
   }
   elsif ($oov) {
      return undef;
   }

   $out =~ s/\@\@//g;
   return $out;
}


sub parse_tokan {
   my $in = shift;
   die "You need to provide a sentence." unless(defined($in));

   my @in = split(/\s+/, $in);
   # Remove the <\/?non-MSA> tags which are part of a token, or the entire
   # token if there is no content other than the tag.
   my @inclean = ();
   foreach my $i (@in){
      $i =~ s/\<non-MSA\>//g;
      $i =~ s/\<\/non-MSA\>//g;
      if ( $i !~ m/^\@\@LAT$sep/){
         push(@inclean, $i);
      }
   }

#   # Escape the middle dots that are not used as separators.  But occur within
#   # words that have not been analyzed
   return join(" ", map { &normalize($_) } @inclean);
}


sub tokenizeArabic {
   my $input = shift;
   die "You need to provide a sentence." unless(defined($input));

   my $word2morpho = shift;
   die "You need to provide a mapping." unless(defined($word2morpho));

   chomp($input);
   # Glue words that ends with a sinble + to its successor.
   $input =~ s/(?<!^)(?<! )(?<!\+)\+ /+/g;
   # Glue words that starts with a sinble + to its predecessor.
   $input =~ s/ \+(?! |\+$)/+/g;


   return join(" ",
        map {
           s/\+/+ /g;
           s/\+/ +/g;
           $word2morpho->{$_} or $_
         } split(/ /, $input));

   my @tok = map { s/\+/+ /g; s/\+/ +/g; $_ } split(/ /, $input);

   my @output;
   foreach my $tok (@tok) {
       # NOTE: using this instead of the if exists means that a word mapping to
       # the empty string will behave has a passthrough instead of a deletion.
       push(@output, ($word2morpho->{$tok} or $tok));

#      if (exists($map->{$tok})) {
#         push(@output, $map->{$tok});
#      }
#      else {
#         #push(@output, "<UNDEFINED>" . $tok . "</UNDEFINED>");
#         push(@output, $tok);
#      }
   }

   return join(" ", @output);
}


# Load MADA's clean up map.
sub loadMADACleanUpMap {
   my $cleanUpMapFile = shift or die "You must provide the location of MADA's clean up map file.";
   my $now_fractions = time;
   if( &MADATools::readUTF8CleanMap($cleanUpMapFile) != 1 ) {
      die "$0: Error - Unable to read UTF-8 cleaning map file $cleanUpMapFile\n";
   }
   printf(STDERR "Loaded clean-up map in %3.3fms\n", 1000 * (time - $now_fractions));
}


sub loadMappingData {
   my $word2morpho = undef;
   unless ($preproOnly) {
      # Load Buckwalter's map.
      warn "Using ", $INC{'tokenize/Arabic/Data.pm'}, " for the tokenization\n";
      my $now_fractions = time;
      $word2morpho  = decode_json( do { local $/; <tokenize::Arabic::Data::DATA>; } );
      printf(STDERR "Loaded morphology in %3.3fms\n", 1000 * (time - $now_fractions));
   }
   return $word2morpho;
}


# Convert hashtags to XML markup: "# nice _ hash" --> "<hashtag> nice hash </hashtag>"
# These will be transfered to the translation via Portage's tag transfer mechanism,
# then converted back to standard hashtag format in postprocess_plugin

sub markHashtags {
   my ($input) = @_;

   # Yes, that's a finite-state machine with operations on transitions :-)
   my $automaton = {
      start => {
         '#' => { op => \&skipToken, opname=>'skip', state => 'hashtagBegin' },
         '_' => { op => \&outputToken, opname=>'output', state => 'start' },
         'any' => { op => \&outputToken, opname=>'output', state => 'start' } },
      hashtagBegin => {
         '#' => { op => \&skipToken, opname=>'skip', , state => 'hashtagBegin' },
         '_' => { op => \&skipToken, opname=>'skip', , state => 'hashtagContinue' },
         'any' => { op => \&storeToken, opname=>'store', state => 'hashtagEnd' } },
      hashtagContinue => {
         '#' => { op => \&flushHashtag, opname=>'flush', state => 'hashtagBegin' },
         '_' => { op => \&skipToken, opname=>'skip', , state => 'hashtagContinue' },
         'any' => { op => \&storeToken, opname=>'store', state => 'hashtagEnd' } },
      hashtagEnd => {
         '#' => { op => \&flushHashtag, opname=>'flush', , state => 'hashtagBegin' },
         '_' => { op => \&skipToken, opname=>'skip', , state => 'hashtagContinue' },
         'any' => { op => \&flushAndOutput, opname=>'flush+output', state => 'start' } },
   };

   my @output = ();
   my @tag = ();
   my $state = 'start';
   for my $token (split(/\s+/, $input)) {
      my $transition = ($token eq '#' or $token eq '_') ? $token : 'any';
      my $op = $automaton->{$state}->{$transition}->{op};
      my $opname = $automaton->{$state}->{$transition}->{opname};
      $op->($token, \@output, \@tag);
#        print STDERR "[$state($token) = $opname";
      $state = $automaton->{$state}->{$transition}->{state};
#        print STDERR " --> $state]\n";
   }
   flushHashtag('', \@output, \@tag);

   return join(" ", @output);
}

sub outputToken {
   my ($tok, $out, $tag) = @_;
   push @$out, $tok;
}

sub skipToken {
   my ($tok, $out, $tag) = @_;
}

sub storeToken {
   my ($tok, $out, $tag) = @_;

   push @$tag, $tok;
}

sub flushHashtag {
   my ($tok, $out, $tag) = @_;

   push @$out, "<hashtag>", @$tag, "</hashtag>"
      if @$tag;
   @$tag = ();
}

sub flushAndOutput {
   flushHashtag(@_);
   outputToken(@_);
}

# Mark tokens containing ascii characters -- these will generate rules in predecode_plugin

sub markNonArabic {
   my ($s) = @_;

   my @out = ();
   for my $token (split(/\s+/, $s)) {
      $token =~ s{^\@\@LAT\@\@(.*)$}{__ascii__$1}g;
      push @out, $token;
   }

   return join(" ", @out);
}


sub debug { printf STDERR @_ if $debug }
