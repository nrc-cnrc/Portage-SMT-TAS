#!/usr/bin/env perl
# @file tokenize_plugin
# @brief  A special tokenize_plugin to replace MADA's slow preprocessing.  This
# scrpts combines all preprocessing steps done for a NIST evaluation.
#
# @author Samuel Larkin
#
# Technologies langagieres interactives / Interactive Language Technologies
# Inst. de technologie de l'information / Institute for Information Technology
# Conseil national de recherches Canada / National Research Council Canada
# Copyright 2014, Sa Majeste la Reine du Chef du Canada /
# Copyright 2014, Her Majesty in Right of Canada


use strict;
use warnings;
use MADA::MADATools;
use ULexiTools;
use JSON;
use Time::HiRes qw ( time );
use FindBin qw($Bin);  # Figures out this script location directory.
# Add this script's path to the end of the include path that way, the effective
# tokenize::Arabic::Data will user defined first then as a fallback we will use
# the default lib located next to this script.
BEGIN { push(@INC, $Bin) }
#warn join(" : ", @INC);
use tokenize::Arabic::Data;


binmode( STDIN,  ":encoding(UTF-8)" );
binmode( STDOUT, ":encoding(UTF-8)" );

sub usage {
   local $, = "\n";
   print STDERR @_, "";
   $0 =~ s#.*/##;
   print STDERR "
Usage: $0 ar [options] [IN [OUT]]

  Tokenization for Arabic text.  This does:
  - Howard's preprocessing to split Arabic from non-Arabic characters
  - MADA's preprocessing
     - clean the UTF-8
     - tag English strings
     - separate punctuation & numbers
     - convert UTF-8 to Buckwalter
  - parse tokan to tokenize latin words
  - perform tokenization by apply a predefined mapping


Notes:
  to be compatible with the normal tokenize_plugin script for portagelive, you
  MUST specify ar as the language code.

Options:

  -p(repoOnly)  do not perform tokenization (do Howard's preprocessing, MADA's preprocessing & parse tokan).
  -h(elp)       print this help message
  -v(erbose)    increment the verbosity level by 1 (may be repeated)
  -d(ebug)      print debugging information
  -q(uiet)      disable verbose messages.
";
   exit 1;
}

use Getopt::Long;
Getopt::Long::Configure("no_ignore_case");
# Note to programmer: Getopt::Long automatically accepts unambiguous
# abbreviations for all options.
my $verbose = 1;
GetOptions(
   help        => sub { usage },
   verbose     => sub { ++$verbose },
   quiet       => sub { $verbose = 0 },
   debug       => \my $debug,
   preproOnly  => \my $preproOnly,
) or usage;

my $SOURCE_LANGUAGE = shift or die "You must provide ar as the language code.";
die "Wrong language, this script is for Arabic only." if (lc($SOURCE_LANGUAGE) ne "ar");


my $MADA_HOME = $ENV{MADA_HOME} || "/opt/PortageII/bin";
print STDERR "MADA_HOME is $MADA_HOME\n";
die "You must define MADA_HOME" unless(defined($MADA_HOME));

# Parse tokan stuff.
my $sep = "Â·";
my $oov = undef;
my $nolc = 0;
my $skipTokenization = undef;

# Make ULexitools arguments explicit by giving them variable names.
my $notok  = 0;
my $pretok = 0;
my $xtags  = 0;
setTokenizationLang("en");



loadMADACleanUpMap("$MADA_HOME/common-tasks/clean-utf8-MAP");
my $map = loadMappingData();

my $now_fractions = time;
while (my $input = <STDIN>) {
   # Howard's preprocessing where we split Arabic characters from non-Arabic characters.
   $input = HowardsPrepro($input);

   # MADA's preprocessing.
   $input = MADAsPrepro($input);

   # Parse tokan.
   $input = parse_tokan($input);

   # Apply the map
   unless ($preproOnly) {
      $input = tokenizeArabic($input, $map);
   }

   print $input if (defined($input));
   print "\n";
}
printf(STDERR "Map in %3.3fms\n", 1000 * (time - $now_fractions));




sub HowardsPrepro {
   my $input = shift or die "You need to provide a sentence.";
   $input =~ s/[\r]?\n$/ /;
   $input =~ s/^/ /;
   $input =~ s/(\p{Script:Arabic}\p{General_Category:Mark}*)([^\p{Script:Arabic}\p{General_Category:Mark}])/$1 $2/g;
   $input =~ s/([^\p{Script:Arabic}\p{General_Category:Mark}])(\p{Script:Arabic}\p{General_Category:Mark}*)/$1 $2/g;
   $input =~ s/  +/ /g;
   $input =~ s/^ //;
   $input =~ s/ $//;

   return $input;
}


sub MADAsPrepro {
   my $input = shift or return;
   my $result = 1;
   ($result, $input) =  &MADATools::cleanUTF8String($input);

   die "$0: Error - Empty UTF8 cleaning map file discovered.\n" if ( $result != 1 );

   $input = &MADATools::tagEnglishInString($input, "tag", "noid");
   $input = &MADATools::separatePunctuationAndNumbers($input, "utf-8", "no");
   $input = &MADATools::convertUTF8ToBuckwalter($input);

   return $input;
}


sub normalize {
   my ($in) = @_;
   my $out = $in;
   if ($out =~ s/\@\@LAT\@\@//g) {
      unless ($skipTokenization) {
         my $para = $out;
         $out = '';
         my @token_positions = tokenize($para, $pretok, $xtags);
         for (my $i = 0; $i < $#token_positions; $i += 2) {
            $out .= " " if ($i > 0);
            $out .= get_collapse_token($para, $i, @token_positions, $notok || $pretok);
         }
         chomp($out);
      }
      $out = lc($out) unless($nolc);
   }
   elsif ($oov) {
      return undef;
   }

   $out =~ s/\@\@//g;
   return $out;
}


sub parse_tokan {
   my $in = shift or return;
   my @in = split(/\s+/, $in);
   # Remove the <\/?non-MSA> tags which are part of a token, or the entire
   # token if there is no content other than the tag.
   my @inclean = ();
   foreach my $i (@in){
      $i =~ s/\<non-MSA\>//g;
      $i =~ s/\<\/non-MSA\>//g;
      if ( $i !~ m/^\@\@LAT$sep/){
         push(@inclean, $i);
      }
   }

   return join(" ", map { &normalize($_) } @inclean);

#   # Escape the middle dots that are not used as separators.  But occur within
#   # words that have not been analyzed
#   my @out = ();
#   foreach my $token (@inclean){
#      push(@out, &normalize($token));
#   }
#
#   return join(" ", @out);
}


sub tokenizeArabic {
   my $input = shift or return;
   my $map = shift or die "You need to provide a mapping.";
   return unless(defined($input));

   chomp($input);
   # Glue words that ends with a sinble + to its successor.
   $input =~ s/(?<!^)(?<! )(?<!\+)\+ /+/g;
   # Glue words that starts with a sinble + to its predecessor.
   $input =~ s/ \+(?! |\+$)/+/g;


   return join(" ",
        map {
           s/\+/+ /g;
           s/\+/ +/g;
           $map->{$_} or $_
         } split(/ /, $input));

   my @tok = map { s/\+/+ /g; s/\+/ +/g; $_ } split(/ /, $input);

   my @output;
   foreach my $tok (@tok) {
       # NOTE: using this instead of the if exists means that a word mapping to
       # the empty string will behave has a passthrough instead of a deletion.
       push(@output, ($map->{$tok} or $tok));

#      if (exists($map->{$tok})) {
#         push(@output, $map->{$tok});
#      }
#      else {
#         #push(@output, "<UNDEFINED>" . $tok . "</UNDEFINED>");
#         push(@output, $tok);
#      }
   }

   return join(" ", @output);
}


# Load MADA's clean up map.
sub loadMADACleanUpMap {
   my $cleanUpMapFile = shift or die "You must provide the location of MADA's clean up map file.";
   my $now_fractions = time;
   if( &MADATools::readUTF8CleanMap($cleanUpMapFile) != 1 ) {
      die "$0: Error - Unable to read UTF-8 cleaning map file $cleanUpMapFile\n";
   }
   printf(STDERR "Loaded clean-up map in %3.3fms\n", 1000 * (time - $now_fractions));
}


sub loadMappingData {
   my $map = undef;
   unless ($preproOnly) {
      # Load Buckwalter's map.
      warn "Using ", $INC{'tokenize/Arabic/Data.pm'}, " for the tokenization\n";
      my $now_fractions = time;
      $map  = decode_json( do { local $/; <tokenize::Arabic::Data::DATA>; } );
      printf(STDERR "Loaded map in %3.3fms\n", 1000 * (time - $now_fractions));
   }
   return $map;
}

